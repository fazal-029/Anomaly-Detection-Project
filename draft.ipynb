{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f285a-0992-457d-9c4c-396057bfd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the mutation and plotting related functions are in the mutation.py file\n",
    "from mutation import * \n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374bf75-3b6a-46d0-adb5-fd0aa74907f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/fazle/notebook-ws/UCR_TimeSeriesAnomalyDatasets2021/AnomalyDatasets_2021/UCR_TimeSeriesAnomalyDatasets2021/FilesAreInHere/UCR_Anomaly_FullData/'\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filter only .txt files\n",
    "txt_files = [file for file in files if file.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dadef-c7a3-4b37-b77d-64eaa3afdc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_records = load_data(txt_files, folder_path, is_record = True, fraction_of_anomaly = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63d05a-de05-4d34-ac88-55fe2b7a9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataset for sequence\n",
    "# dataset_seq = load_data(txt_files, folder_path, is_record = False, fraction_of_anomaly = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955f53c-2299-4347-a117-440fddba0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Define the custom F1 score metric\n",
    "def f1_score_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred_binary = tf.round(y_pred)  # Convert predictions to binary values\n",
    "    y_pred_binary = tf.cast(y_pred_binary, tf.float32)\n",
    "\n",
    "    tp = K.sum(K.cast(y_true * y_pred_binary, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred_binary, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred_binary), 'float'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    return f1\n",
    "\n",
    "# Define the function to train and evaluate the MLP model\n",
    "def train_and_evaluate_mlp(df_tuple):\n",
    "    # Extract features and labels\n",
    "    X = df_tuple[0]['feature'].values.reshape(-1, 1)\n",
    "    y = df_tuple[0]['is_anomaly'].values\n",
    "    last_training_data = df_tuple[1]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = X[:last_training_data], X[last_training_data:], y[:last_training_data], y[last_training_data:]\n",
    "\n",
    "    # Define the more complex MLP model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1_score_metric])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0.0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "# List to store the F1 score results\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for i, df in enumerate(dataset_records):\n",
    "    print(f'Training and evaluating on dataset {i+1}')\n",
    "    precision, recall, f1, accuracy = train_and_evaluate_mlp(df)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Dataset {i+1} Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate the average precision, recall, and F1 score across all datasets\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1_score = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "print(f'Average Precision: {average_precision:.4f}')\n",
    "print(f'Average Recall: {average_recall:.4f}')\n",
    "print(f'Average F1 Score: {average_f1_score:.4f}')\n",
    "print(f'Average Accuracy: {average_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bc820-c0c8-4f92-b141-36e83097daf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a7cb9-82e9-4d96-b843-7333805e86be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a35fea-9a19-4fa3-a68e-5fd3e569975b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e8a06e2-6bba-450c-be84-27089277360d",
   "metadata": {},
   "source": [
    "# Anomalous sequence detection - semi supervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f51cc5-3317-4fbc-9e8f-577d3c14f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_lstm_autoencoder(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='relu', return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32, activation='relu', return_sequences=False),\n",
    "        RepeatVector(input_shape[0]),\n",
    "        LSTM(32, activation='relu', return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64, activation='relu', return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(input_shape[1]))\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def fit_lstm_autoencoder(model, train_data, epochs=50, batch_size=32):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(train_data, train_data, epochs=epochs, verbose=0, batch_size=batch_size, \n",
    "              validation_split=0.1, callbacks=[early_stopping], shuffle=False)\n",
    "    return model\n",
    "\n",
    "def create_sequences(data, timesteps):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - timesteps + 1):\n",
    "        sequence = data[i:i + timesteps]\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "def is_prediction_correct(prediction, begin, end):\n",
    "    print(f'prediction: {prediction}, begin: {begin}, end: {end}')\n",
    "    L = end - begin + 1\n",
    "    return min(begin - L, begin - 100) < prediction < max(end + L, end + 100)\n",
    "\n",
    "def detect_anomaly(model, test_data, segment_length):\n",
    "    predictions = model.predict(test_data)\n",
    "    reconstruction_errors = np.mean(np.abs(predictions - test_data), axis=1)\n",
    "    segment_errors = []\n",
    "\n",
    "    # Calculate average error for each segment\n",
    "    for i in range(len(reconstruction_errors) - segment_length + 1):\n",
    "        segment_error = np.mean(reconstruction_errors[i:i + segment_length])\n",
    "        segment_errors.append(segment_error)\n",
    "\n",
    "    # Find the segment with the highest average error\n",
    "    most_confident_anomalous_segment = np.argmax(segment_errors)\n",
    "    center_of_anomalous_segment = most_confident_anomalous_segment + segment_length // 2\n",
    "\n",
    "    return center_of_anomalous_segment\n",
    "\n",
    "def train_and_evaluate_lstm_autoencoder(df_tuple, timesteps, segment_length):\n",
    "    X = df_tuple[0]['feature'].values\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "    \n",
    "    train_data, test_data = X[:last_training_data], X[last_training_data:]\n",
    "\n",
    "    # Create sequences\n",
    "    train_data = create_sequences(train_data, timesteps)\n",
    "    test_data = create_sequences(test_data, timesteps)\n",
    "    \n",
    "    # Reshape data for LSTM\n",
    "    train_data = train_data.reshape((train_data.shape[0], timesteps, 1))\n",
    "    test_data = test_data.reshape((test_data.shape[0], timesteps, 1))\n",
    "    \n",
    "    # Create and train the LSTM-Autoencoder\n",
    "    model = create_lstm_autoencoder((timesteps, 1))\n",
    "    model = fit_lstm_autoencoder(model, train_data)\n",
    "    \n",
    "    # Detect anomalies in the test set\n",
    "    center_of_anomalous_segment = detect_anomaly(model, test_data, segment_length) + last_training_data\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    correct = is_prediction_correct(center_of_anomalous_segment, begin_anomaly, end_anomaly)\n",
    "    print(f'last training point: {last_training_data}')\n",
    "    return correct\n",
    "\n",
    "# Example number of timesteps and segment length\n",
    "timesteps = 30\n",
    "segment_length = 30\n",
    "\n",
    "dataset_seq_wo_mutation = load_data(txt_files, folder_path, is_record=False, fraction_of_anomaly=0.02, mutation=False)\n",
    "results = []\n",
    "\n",
    "for i, df in enumerate(dataset_seq_wo_mutation):\n",
    "    print(f'Training and evaluating on dataset {i + 1}')\n",
    "    correct_or_not = train_and_evaluate_lstm_autoencoder(df, timesteps, segment_length)\n",
    "    results.append(correct_or_not)\n",
    "    print(f'Dataset {i + 1} correctly identified: {correct_or_not}')\n",
    "\n",
    "accuracy = sum(1 for item in results if item) / len(results)\n",
    "print(f'Final Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c2143-f1a8-4bdb-a783-18f4075c5215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a9dae-3db8-470a-94c7-b2d5bcdc69fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56241f6f-0759-4f24-9c16-0c98b3afbaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110bfd6-c90b-458c-8534-2be6b4a3ab13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
