{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524f285a-0992-457d-9c4c-396057bfd3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 04:31:56.258622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 04:31:56.271188: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 04:31:56.274839: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 04:31:56.284390: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 04:31:57.080930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from mutation import * \n",
    "from utility_functions import *\n",
    "from models import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374bf75-3b6a-46d0-adb5-fd0aa74907f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/fazle/notebook-ws/UCR_TimeSeriesAnomalyDatasets2021/AnomalyDatasets_2021/UCR_TimeSeriesAnomalyDatasets2021/FilesAreInHere/UCR_Anomaly_FullData/'\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filter only .txt files\n",
    "txt_files = [file for file in files if file.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d94517-3787-4715-a4ca-3bd589b80cbc",
   "metadata": {},
   "source": [
    "# Time Series Modeling - Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07cd9fa-5775-47d7-b745-87f95a5d0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_seq = load_data(txt_files, folder_path, is_record = False, fraction_of_anomaly = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcaafc8-61ca-4bf1-b04a-3190e4b90c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_for_each_dataset(model, df_tuple, window_size=30, threshold=0.10, cls_weight = 20.0):\n",
    "    X = df_tuple[0]['feature'].values\n",
    "    y = df_tuple[0]['is_anomaly'].values\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # X = scaler.fit_transform(X.reshape(-1, 1)).flatten()\n",
    "    X[:last_training_data] = scaler.fit_transform(X[:last_training_data].reshape(-1, 1)).flatten()\n",
    "    X[last_training_data:] = scaler.transform(X[last_training_data:].reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Create sequences - Assuming create_sequences_w_labels returns a 2D array\n",
    "    X_sequences, y_sequences = create_sequences_w_labels(X, y, window_size)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test = X_sequences[:last_training_data - window_size], X_sequences[last_training_data - window_size:]\n",
    "    y_train, y_test = y_sequences[:last_training_data - window_size], y_sequences[last_training_data - window_size:]\n",
    "    class_weights = {0:1.0, 1:cls_weight}\n",
    "    model.fit(X_train, y_train, epochs=80, verbose=0, batch_size=30, shuffle = False, class_weight = class_weights)\n",
    "    \n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    correct_or_not = is_prediction_correct((np.argmax(y_pred) + last_training_data), begin_anomaly, end_anomaly)\n",
    "    y_pred = (y_pred > threshold).astype(int)\n",
    "    specificity = custom_specificity(y_test, y_pred, tolerance=end_anomaly - begin_anomaly)\n",
    "    return correct_or_not, specificity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b23aa-2f0c-4ae0-8882-10926bdd0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_for_model(model, dataset_seq, window_size=50, threshold=0.10, cls_weight = 15.0):\n",
    "    accuracy_scores = []\n",
    "    specificity_scores = []\n",
    "        \n",
    "    for i, df in enumerate(dataset_seq):\n",
    "        print(f'Training and evaluating on dataset {i+1}')\n",
    "        accuracy, specificity = get_result_for_each_dataset(model, df, window_size, threshold, cls_weight)\n",
    "        specificity_scores.append(specificity)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        print(f'Dataset {i+1} specificity: {specificity:.4f} Correctly_predicted ------------- {accuracy}')\n",
    "        \n",
    "        # Calculate the average precision, recall, and F1 score across all datasets\n",
    "    average_specificity = np.mean(specificity_scores)\n",
    "    average_accuracy =  sum(1 for item in accuracy_scores if item == True) / len(accuracy_scores)\n",
    "    print(f'Average specificity: {average_specificity:.4f} ')\n",
    "    print(f'Average Accuracy: {average_accuracy:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d16f4a-720f-443a-a429-9887ecc1dfa0",
   "metadata": {},
   "source": [
    "**Multi Layer Perceptron-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15589f19-a575-4bc7-a445-ddb63eaaeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp2(window_size = 50)\n",
    "get_result_for_model(model, dataset_seq, window_size=50, threshold=0.10, cls_weight = 15.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0e9f6-ed00-4657-997d-d255b154c28f",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9242fd-e438-476c-a454-6a2633c49e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm(window_size = 40)\n",
    "get_result_for_model(model, dataset_seq, window_size=40, threshold=0.10, cls_weight = 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03580c2c-33b0-47ac-9973-668cb439cfc1",
   "metadata": {},
   "source": [
    "**BI-LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdbd6d-e2a6-493f-840d-7639c4320d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bi_lstm(window_size = 30)\n",
    "get_result_for_model(model, dataset_seq, window_size=30, threshold=0.10, cls_weight = 15.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c70c9a-5b36-4e54-b004-fbe7e657be96",
   "metadata": {},
   "source": [
    "**Gated Recurrent Unit (GRU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0bb6b-a28e-42bc-b984-b804da024151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gru(window_size = 30)\n",
    "get_result_for_model(model, dataset_seq, window_size=30, threshold=0.10, cls_weight = 15.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0484cd4-ef6c-4a59-a9e6-12c0c88bf034",
   "metadata": {},
   "source": [
    "**Support Vector Machine (SVM2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c472c-fd1d-4187-a77c-7fcb35a14984",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_svm(dataset_seq, window_size=100, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a36a9-4648-4d3a-a017-d6022089da8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cdba1b2-39af-4a85-9eb6-8f5939b78cc3",
   "metadata": {},
   "source": [
    "# Anomalous sequence detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d6ebe-2634-4d3e-b462-df5fa97dbe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_seq_wo_mutation = load_data(txt_files, folder_path, mutation_done=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a06e2-6bba-450c-be84-27089277360d",
   "metadata": {},
   "source": [
    "# semi supervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11895f5-9467-45c3-aa11-3f37d1c7d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_seq_models(model, df_tuple, timesteps, segment_length):\n",
    "    X = df_tuple[0]['feature'].values\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "    \n",
    "    train_data, test_data = X[:last_training_data], X[last_training_data:]\n",
    "\n",
    "    # Create sequences\n",
    "    train_data = create_sequences_wo_labels(train_data, timesteps)\n",
    "    test_data = create_sequences_wo_labels(test_data, timesteps)\n",
    "    \n",
    "    # Reshape data for LSTM\n",
    "    train_data = train_data.reshape((train_data.shape[0], timesteps, 1))\n",
    "    test_data = test_data.reshape((test_data.shape[0], timesteps, 1))\n",
    "    \n",
    "    model.fit(train_data, train_data, epochs=70, verbose=0, batch_size=32, shuffle=False)\n",
    "    \n",
    "    center_of_anomalous_segment = detect_anomaly(model, test_data, segment_length) + last_training_data\n",
    "    \n",
    "    correct = is_prediction_correct(center_of_anomalous_segment, begin_anomaly, end_anomaly)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc97b82-3c3c-4119-a794-aba7c809a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model (model_c, dataset_seq, time_steps, seg_length):\n",
    "    results = []\n",
    "    for i, df in enumerate(dataset_seq):\n",
    "        print(f'Training and evaluating on dataset {i + 1}')\n",
    "        correct_or_not = train_and_evaluate_seq_models(model_c, df, time_steps, seg_length)\n",
    "        results.append(correct_or_not)\n",
    "        print(f'Dataset {i + 1} correctly identified:--------------- {correct_or_not}')\n",
    "    \n",
    "    accuracy = sum(1 for item in results if item == True) / len(results)\n",
    "    print(f'Final Accuracy: {accuracy}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3ab75-6b76-41d9-b30d-31b6d2534746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 & 30 works best for LSTM Autoencoder among all the numbers I have tried.\n",
    "timesteps = 30\n",
    "segment_length = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1070a-39f5-4d9a-aed4-33dbcae9a516",
   "metadata": {},
   "source": [
    "**LSTM Autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236700e-96ad-41c7-9e1e-73127fe265fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm_autoencoder((timesteps, 1))\n",
    "evaluate_model(model, dataset_seq_wo_mutation, timesteps, segment_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11445fbf-60d5-4206-9e8b-6d900e2916e7",
   "metadata": {},
   "source": [
    "**Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1cd08-aaaf-4186-87b3-114a2d136061",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 30\n",
    "segment_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28fee9-b356-4988-9a03-22de16a97acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_transformer_autoencoder((timesteps, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21400076-2dab-462c-86f0-65ae15f768a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, dataset_seq_wo_mutation, timesteps, segment_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9437a69-c916-4b34-a9f1-9c6ebf5070c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    head_size = trial.suggest_int('head_size', 32, 128, step=32)\n",
    "    num_heads = trial.suggest_int('num_heads', 2, 8, step=2)\n",
    "    ff_dim = trial.suggest_int('ff_dim', 32, 128, step=32)\n",
    "    num_transformer_blocks = trial.suggest_int('num_transformer_blocks', 1, 4)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5, step=0.1)\n",
    "\n",
    "    input_shape = (timesteps, 1)\n",
    "    model = create_transformer_autoencoder(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, dropout)\n",
    "    \n",
    "    accuracy = evaluate_model(model, dataset_seq_wo_mutation, timesteps, segment_length)\n",
    "    \n",
    "    return -accuracy  # Since Optuna minimizes the objective, use the negative accuracy\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb84075-9a55-4a68-bfdb-c619e8a559b2",
   "metadata": {},
   "source": [
    "# Time Series Modeling - Statistical Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb531ee5-a3e5-4f6b-8fe8-a6d6362c8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cf900-ec30-42c8-bce5-dd38e9a2063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Augmented Dickey-Fuller (ADF) test\n",
    "for i, df in enumerate(dataset_seq_wo_mutation):\n",
    "    X = df[0]\n",
    "    last_training_data = df[1]\n",
    "    train_data = X[:last_training_data]\n",
    "    \n",
    "    result = adfuller(train_data['feature'])\n",
    "    print(f'ADF Statistic for dataset {i} is : {result[0]}')\n",
    "    print('p-value:', result[1])\n",
    "    \n",
    "    for key, value in result[4].items():\n",
    "        print('Critical Value {}: {}'.format(key, value))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01990d7-b987-4c8b-8371-55c95e9b4e48",
   "metadata": {},
   "source": [
    "**Autoregressive (AR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc39bf0a-3dda-48d5-ab88-ce4569b18e99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_seq_wo_mutation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[0;32m---> 47\u001b[0m evaluate_statistical_model_ar(\u001b[43mdataset_seq_wo_mutation\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_seq_wo_mutation' is not defined"
     ]
    }
   ],
   "source": [
    "def select_ar_model(time_series):\n",
    "    best_aic = float(\"inf\")\n",
    "    best_lag = None\n",
    "    best_model = None\n",
    "\n",
    "    lags = [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 100, 200]\n",
    "    for l in lags:\n",
    "        model = AutoReg(time_series['feature'], lags=l).fit()\n",
    "        aic = model.aic\n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_lag = l\n",
    "            best_model = model\n",
    "\n",
    "    print(f'best lag for this time series is --------------- {best_lag}')\n",
    "    return best_lag, best_model\n",
    "\n",
    "def handle_each_time_series_ar(df_tuple):\n",
    "    X = df_tuple[0]\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "    train_data, test_data = X[:last_training_data], X[last_training_data:]\n",
    "    \n",
    "    best_lag, model = select_ar_model(train_data)\n",
    "    predictions = model.predict(start=best_lag, end=len(test_data) - 1, dynamic=False)\n",
    "    \n",
    "    # Calculate residuals (actual - predicted)\n",
    "    residuals = test_data['feature'][best_lag:] - predictions\n",
    "    anomaly_position = residuals.idxmax()\n",
    "    correct_or_not = is_prediction_correct(anomaly_position, begin_anomaly, end_anomaly)\n",
    "    return correct_or_not\n",
    "\n",
    "\n",
    "def evaluate_statistical_model_ar(dataset_seq):\n",
    "    results = []\n",
    "    for i, df in enumerate(dataset_seq):\n",
    "        print(f'Training and evaluating on dataset {i + 1}')\n",
    "        correct_or_not = handle_each_time_series_ar(df)\n",
    "        results.append(correct_or_not)\n",
    "        print(f'Dataset {i + 1} correctly identified: {correct_or_not}')\n",
    "    \n",
    "    accuracy = sum(1 for item in results if item == True) / len(results)\n",
    "    print(f'Final Accuracy: {accuracy}')\n",
    "    return accuracy\n",
    "\n",
    "evaluate_statistical_model_ar(dataset_seq_wo_mutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2715ef-e5e8-4d4b-a758-5d6c2a3fc5a5",
   "metadata": {},
   "source": [
    "**Moving Average (MA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8c0c4-2d2e-4607-8e82-ecd82e3c3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_each_time_series_ma(df_tuple):\n",
    "    X = df_tuple[0]\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "    train_data, test_data = X[:last_training_data], X[last_training_data:]\n",
    "    window_size = 10 \n",
    "\n",
    "    moving_average = train_data['feature'].rolling(window=window_size).mean()\n",
    "    moving_average = moving_average.dropna()\n",
    "\n",
    "    # The moving average will have `window_size - 1` fewer entries, so adjusting accordingly\n",
    "    predictions_train = moving_average.reset_index(drop=True)\n",
    "    predictions_train = predictions_train[window_size - 1:]  # Align predictions with the end of the training data\n",
    "\n",
    "    last_moving_average = moving_average.iloc[-1]\n",
    "    predictions_test = [last_moving_average] * len(test_data)\n",
    "\n",
    "    predictions = list(predictions_train) + predictions_test\n",
    "\n",
    "    actual_values = train_data['feature'][window_size - 1:].tolist() + test_data['feature'].tolist()\n",
    "    residuals = [actual - predicted for actual, predicted in zip(actual_values, predictions)]\n",
    "\n",
    "    residuals = residuals[len(predictions_train):]\n",
    "    anomaly_position = residuals.index(max(residuals)) + len(predictions_train)  # Adjust for alignment\n",
    "\n",
    "    correct_or_not = is_prediction_correct(anomaly_position, begin_anomaly, end_anomaly)\n",
    "    return correct_or_not\n",
    "\n",
    "def evaluate_statistical_model_ma(dataset_seq):\n",
    "    results = []\n",
    "    for i, df in enumerate(dataset_seq):\n",
    "        print(f'Training and evaluating on dataset {i + 1}')\n",
    "        correct_or_not = handle_each_time_series_ma(df)\n",
    "        results.append(correct_or_not)\n",
    "        print(f'Dataset {i + 1} correctly identified: {correct_or_not}')\n",
    "    \n",
    "    accuracy = sum(1 for item in results if item == True) / len(results)\n",
    "    print(f'Final Accuracy: {accuracy}')\n",
    "    return accuracy\n",
    "\n",
    "evaluate_statistical_model_ma(dataset_seq_wo_mutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80568b5-e60c-45a1-8af8-85334c40b475",
   "metadata": {},
   "source": [
    "**Autoregressive Integrated Moving Average (ARIMA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c288a8-b13a-4cfc-8228-8fe9a0a37f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_arima_model(time_series, max_p, max_q):\n",
    "    best_aic = float(\"inf\")\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "\n",
    "    for p in range(max_p + 1):\n",
    "        for q in range(max_q + 1):\n",
    "            try:\n",
    "                model = ARIMA(time_series, order=(p, 0, q)).fit()\n",
    "                aic = model.aic\n",
    "                if aic < best_aic:\n",
    "                    best_aic = aic\n",
    "                    best_order = (p, 0, q)\n",
    "                    best_model = model\n",
    "            except:\n",
    "                continue\n",
    "    print(f'best order for this time series: {best_order}')\n",
    "    return best_order, best_model\n",
    "\n",
    "\n",
    "def handle_each_time_series_arima(df_tuple):\n",
    "    X = df_tuple[0]\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "    train_data, test_data = X[:last_training_data], X[last_training_data:]\n",
    "\n",
    "    best_order, model = select_arima_model(train_data['feature'], max_p=5, max_q=5)\n",
    "\n",
    "    # We need to adjust the start and end parameters for predictions\n",
    "    start = len(train_data)\n",
    "    end = start + len(test_data) - 1\n",
    "    predictions = model.predict(start=start, end=end, dynamic=False)\n",
    "\n",
    "    # Calculate residuals (actual - predicted)\n",
    "    residuals = test_data['feature'] - predictions\n",
    "    anomaly_position = residuals.idxmax()\n",
    "    correct_or_not = is_prediction_correct(anomaly_position, begin_anomaly, end_anomaly)\n",
    "    return correct_or_not\n",
    "\n",
    "def evaluate_statistical_model_arima(dataset_seq):\n",
    "    results = []\n",
    "    for i, df in enumerate(dataset_seq):\n",
    "        print(f'Training and evaluating on dataset {i + 1}')\n",
    "        correct_or_not = handle_each_time_series_arima(df)\n",
    "        results.append(correct_or_not)\n",
    "        print(f'Dataset {i + 1} correctly identified: {correct_or_not}')\n",
    "    \n",
    "    accuracy = sum(1 for item in results if item == True) / len(results)\n",
    "    print(f'Final Accuracy: {accuracy}')\n",
    "    return accuracy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_statistical_model_arima(dataset_seq_wo_mutation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b15f5-debc-4572-9304-5b88f90c324c",
   "metadata": {},
   "source": [
    "**Holt-Winters (HW)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4f6c2-15d9-4fb8-9fe2-8c18ab1de505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_hw_model(time_series):\n",
    "    best_aic = float(\"inf\")\n",
    "    best_seasonal_period = None\n",
    "    best_model = None\n",
    "\n",
    "    seasonal_periods = [5, 20, 35, 50, 65]\n",
    "    for period in seasonal_periods:\n",
    "        try:\n",
    "            model = ExponentialSmoothing(\n",
    "                time_series['feature'], \n",
    "                seasonal_periods=period, \n",
    "                trend='add', \n",
    "                seasonal='add'\n",
    "            ).fit()\n",
    "            aic = model.aic\n",
    "            if aic < best_aic:\n",
    "                best_aic = aic\n",
    "                best_seasonal_period = period\n",
    "                best_model = model\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping seasonal period {period} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f'Best seasonal period for this time series is --------------- {best_seasonal_period}')\n",
    "    return best_seasonal_period, best_model\n",
    "\n",
    "def handle_each_time_series_hw(df_tuple):\n",
    "    X = df_tuple[0]\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "    train_data, test_data = X[:last_training_data], X[last_training_data:]\n",
    "\n",
    "    best_seasonal_period, model = select_hw_model(train_data)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.forecast(steps=len(test_data))\n",
    "\n",
    "    # Calculate residuals (actual - predicted)\n",
    "    residuals = test_data['feature'] - predictions\n",
    "    anomaly_position = residuals.idxmax()\n",
    "    correct_or_not = is_prediction_correct(anomaly_position, begin_anomaly, end_anomaly)\n",
    "    return correct_or_not\n",
    "\n",
    "def evaluate_statistical_model_hw(dataset_seq):\n",
    "    results = []\n",
    "    for i, df in enumerate(dataset_seq):\n",
    "        print(f'Training and evaluating on dataset {i + 1}')\n",
    "        correct_or_not = handle_each_time_series_hw(df)\n",
    "        results.append(correct_or_not)\n",
    "        print(f'Dataset {i + 1} correctly identified: {correct_or_not}')\n",
    "    \n",
    "    accuracy = sum(1 for item in results if item) / len(results)\n",
    "    print(f'Final Accuracy: {accuracy}')\n",
    "    return accuracy\n",
    "\n",
    "evaluate_statistical_model_hw(dataset_seq_wo_mutation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87965ca-3960-432e-af49-0ebdbfa4c16f",
   "metadata": {},
   "source": [
    "# Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b0278-d379-42da-b250-516e5c9b106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ed15f-bee8-4295-a9a8-a8af4f655ecd",
   "metadata": {},
   "source": [
    "**Seasonal-Trend decomposition using LOESS (STL)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de56394-04c8-40c8-8cb7-91083883a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def estimate_period(time_series):\n",
    "    autocorr = acf(time_series, nlags=len(time_series)//2)\n",
    "    period = np.argmax(autocorr[1:]) + 1\n",
    "    if period < 2:\n",
    "        period = 2\n",
    "    return period\n",
    "\n",
    "def select_stl_model(time_series, period):\n",
    "    stl = STL(time_series['feature'], period=period, seasonal=3)\n",
    "    result = stl.fit()\n",
    "    \n",
    "    trend = result.trend\n",
    "    seasonal = result.seasonal\n",
    "    residual = result.resid\n",
    "    n = len(residual)\n",
    "    rss = np.sum(residual**2)\n",
    "    aic = n * np.log(rss / n) + 2 * 2  # 2 for trend and seasonal components\n",
    "    \n",
    "    return trend, seasonal, residual, aic\n",
    "\n",
    "def forecast_stl_components(trend, seasonal, test_length, period):\n",
    "    if len(trend) == 0 or len(seasonal) == 0:\n",
    "        raise ValueError(\"Trend or Seasonal components are empty.\")\n",
    "    \n",
    "    # Extend the trend by repeating the last value\n",
    "    trend_forecast = np.append(trend, [trend.iloc[-1]] * test_length)\n",
    "    \n",
    "    # Extend the seasonal component by repeating the seasonal pattern\n",
    "    seasonal_pattern = seasonal[-period:]\n",
    "    seasonal_forecast = np.tile(seasonal_pattern, (test_length // period) + 1)[:test_length]\n",
    "    \n",
    "    return trend_forecast[-test_length:], seasonal_forecast\n",
    "\n",
    "def handle_each_time_series_stl(df_tuple):\n",
    "    X = df_tuple[0]\n",
    "    last_training_data = df_tuple[1]\n",
    "    begin_anomaly = df_tuple[2]\n",
    "    end_anomaly = df_tuple[3]\n",
    "    train_data, test_data = X[:last_training_data], X[last_training_data:]\n",
    "\n",
    "    # Estimate the period for the current time series\n",
    "    period = estimate_period(train_data['feature'])\n",
    "    \n",
    "    trend, seasonal, residual, aic = select_stl_model(train_data, period)\n",
    "    \n",
    "    # Forecast the trend and seasonal components for the test period\n",
    "    trend_forecast, seasonal_forecast = forecast_stl_components(trend, seasonal, len(test_data), period)\n",
    "    prediction = trend_forecast + seasonal_forecast\n",
    "    \n",
    "    # Calculate residuals (actual - predicted)\n",
    "    residuals = test_data['feature'].values - prediction\n",
    "    anomaly_position = residuals.argmax()\n",
    "    correct_or_not = is_prediction_correct(anomaly_position, begin_anomaly, end_anomaly)\n",
    "    return correct_or_not\n",
    "\n",
    "def evaluate_statistical_model_stl(dataset_seq):\n",
    "    results = []\n",
    "    for i, df in enumerate(dataset_seq):\n",
    "        print(f'Training and evaluating on dataset {i + 1}')\n",
    "        correct_or_not = handle_each_time_series_stl(df)\n",
    "        results.append(correct_or_not)\n",
    "        print(f'Dataset {i + 1} correctly identified ------------ {correct_or_not}')\n",
    "    \n",
    "    accuracy = sum(1 for item in results if item) / len(results)\n",
    "    print(f'Final Accuracy: {accuracy}')\n",
    "    return accuracy\n",
    "\n",
    "# Example usage with your dataset\n",
    "evaluate_statistical_model_stl(dataset_seq_wo_mutation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b1ff2-f780-46a6-976b-faeca97f0149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
