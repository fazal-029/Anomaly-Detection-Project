{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4331fe-88a1-4c69-8660-ea6fac64fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from mutation_multivariate import *\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Masking, GRU, Flatten\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab4a145-d0af-4aea-ab5c-8c5356a6c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52,)\n",
      "(52,)\n",
      "(31,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.load('spark_0_trace-scl_std/train.npy', allow_pickle=True)\n",
    "test_x = np.load('spark_0_trace-scl_std/test.npy', allow_pickle=True)\n",
    "train_y = np.load('spark_0_trace-scl_std/y_train.npy', allow_pickle=True)\n",
    "test_y = np.load('spark_0_trace-scl_std/y_test.npy', allow_pickle=True)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3f8c35-7fda-4578-8f4c-da10529dd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, _ in enumerate(test_y):\n",
    "    test_y[j] = (test_y[j] != 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa55754c-b621-4a17-90eb-ad935ecb4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Injecting anomaly using mutation\n",
    "train_x, train_y = load_multivariate_mutated(train_x, train_y, record = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccf61d-e821-4918-bdb6-ace6be9f88ba",
   "metadata": {},
   "source": [
    "**MLP2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "714e75fe-66aa-4457-a00c-5ab37b02a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazle/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 604us/step\n",
      "\n",
      "Epoch 1: AUC-PR improved to 0.1248. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.9685 - loss: 2.1528 - val_accuracy: 0.9816 - val_loss: 0.1399\n",
      "Epoch 2/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step\n",
      "\n",
      "Epoch 2: AUC-PR improved to 0.3190. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.9016 - loss: 0.9332 - val_accuracy: 0.9727 - val_loss: 0.1694\n",
      "Epoch 3/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.9739 - loss: 0.5144 - val_accuracy: 0.9814 - val_loss: 0.0959\n",
      "Epoch 4/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.9785 - loss: 0.4480 - val_accuracy: 0.9800 - val_loss: 0.2217\n",
      "Epoch 5/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.2698 - val_accuracy: 0.9800 - val_loss: 0.2339\n",
      "Epoch 6/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.2180 - val_accuracy: 0.9793 - val_loss: 0.2380\n",
      "Epoch 7/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.9843 - loss: 0.1939 - val_accuracy: 0.9797 - val_loss: 0.1765\n",
      "Epoch 8/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.9834 - loss: 0.2002 - val_accuracy: 0.9699 - val_loss: 0.1912\n",
      "Epoch 9/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.9856 - loss: 0.1540 - val_accuracy: 0.9660 - val_loss: 0.1562\n",
      "Epoch 10/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.9859 - loss: 0.1301 - val_accuracy: 0.9628 - val_loss: 0.1614\n",
      "Epoch 11/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.9862 - loss: 0.1318 - val_accuracy: 0.9517 - val_loss: 0.1939\n",
      "Epoch 12/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.1549 - val_accuracy: 0.9641 - val_loss: 0.1882\n",
      "Epoch 13/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.9860 - loss: 0.0975 - val_accuracy: 0.9544 - val_loss: 0.2242\n",
      "Epoch 14/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.9875 - loss: 0.0882 - val_accuracy: 0.9540 - val_loss: 0.4069\n",
      "Epoch 15/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9871 - loss: 0.0973 - val_accuracy: 0.9562 - val_loss: 0.2196\n",
      "Epoch 16/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.9840 - loss: 0.1087 - val_accuracy: 0.9617 - val_loss: 0.2221\n",
      "Epoch 17/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.9887 - loss: 0.0651 - val_accuracy: 0.9642 - val_loss: 0.2251\n",
      "Epoch 18/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.9930 - loss: 0.0611 - val_accuracy: 0.9429 - val_loss: 0.5816\n",
      "Epoch 19/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.9848 - loss: 0.1132 - val_accuracy: 0.9608 - val_loss: 0.2612\n",
      "Epoch 20/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.9935 - loss: 0.0489 - val_accuracy: 0.9726 - val_loss: 0.2344\n",
      "Epoch 21/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9935 - loss: 0.0407 - val_accuracy: 0.9708 - val_loss: 0.2702\n",
      "Epoch 22/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9926 - loss: 0.0476 - val_accuracy: 0.9709 - val_loss: 0.2716\n",
      "Epoch 23/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.9951 - loss: 0.0328 - val_accuracy: 0.9705 - val_loss: 0.3137\n",
      "Epoch 24/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0283 - val_accuracy: 0.9677 - val_loss: 0.3484\n",
      "Epoch 25/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.9942 - loss: 0.0228 - val_accuracy: 0.9750 - val_loss: 0.3142\n",
      "Epoch 26/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.9948 - loss: 0.0243 - val_accuracy: 0.9697 - val_loss: 0.3151\n",
      "Epoch 27/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.9951 - loss: 0.0252 - val_accuracy: 0.9604 - val_loss: 0.6285\n",
      "Epoch 28/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9912 - loss: 0.1472 - val_accuracy: 0.9599 - val_loss: 0.5212\n",
      "Epoch 29/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.9957 - loss: 0.0331 - val_accuracy: 0.9647 - val_loss: 0.4226\n",
      "Epoch 30/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.9965 - loss: 0.0181 - val_accuracy: 0.9666 - val_loss: 0.7043\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step\n",
      "Average AUC-PR: 0.10476571112322149\n"
     ]
    }
   ],
   "source": [
    "# Function to create input sequences\n",
    "def create_input_sequences_f(data, labels, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequence = np.array(data[i:i + sequence_length]).flatten()  # Flatten the sequence\n",
    "        sequences.append(sequence)\n",
    "        targets.append(labels[i + sequence_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "auc_prs = []\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 5\n",
    "\n",
    "# Stack and preprocess all training samples\n",
    "stacked_train_x = np.vstack(train_x)\n",
    "stacked_train_y = np.concatenate(train_y)\n",
    "\n",
    "# Create sequences from stacked training samples\n",
    "s_train_x, s_train_y = create_input_sequences_f(stacked_train_x, stacked_train_y, sequence_length)\n",
    "\n",
    "model_save_path = 'mlp_best.weights.h5'\n",
    "auc_pr_callback = AUC_PR_Callback(validation_data=(s_train_x, s_train_y), model_save_path=model_save_path)\n",
    "\n",
    "# Ensure the input shape is correct\n",
    "input_shape = (sequence_length * 19,)\n",
    "\n",
    "# Define the MLP model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=input_shape),  # Adjust input shape for flattened sequence\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "class_weights = {0: 1.0, 1: 5.0}\n",
    "model.fit(s_train_x, s_train_y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[auc_pr_callback], \n",
    "          shuffle=False, class_weight=class_weights)\n",
    "model.load_weights(model_save_path)\n",
    "\n",
    "# Iterate over test_x to evaluate and calculate metrics\n",
    "auc_prs = []  # Reinitialize to avoid appending to previous results\n",
    "for i in range(len(test_x)):\n",
    "    if len(test_x[i]) > sequence_length:\n",
    "        # Create sequences for the current test sample\n",
    "        s_test_x, s_test_y = create_input_sequences(test_x[i], test_y[i], sequence_length)\n",
    "        \n",
    "        # Ensure the test input shape is correct\n",
    "        s_test_x = s_test_x.reshape((-1, input_shape[0]))\n",
    "\n",
    "        # Predict on the test data\n",
    "        test_predictions = model.predict(s_test_x).reshape(-1)\n",
    "        \n",
    "        # Assuming `get_auc_pr` function is defined to calculate AUC-PR\n",
    "        auc_pr = get_auc_pr(test_predictions, s_test_y)\n",
    "        \n",
    "        auc_prs.append(auc_pr)\n",
    "\n",
    "avg_auc_pr = np.mean(auc_prs)\n",
    "\n",
    "print(f'Average AUC-PR: {avg_auc_pr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d441c5e-af2f-4800-b2a1-f22981eb7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create input sequences\n",
    "def create_input_sequences(data, labels, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequence = np.array(data[i:i + sequence_length])\n",
    "        sequences.append(sequence)\n",
    "        targets.append(labels[i + sequence_length])\n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9eccd-2e6c-433d-b55e-fb35a4090e29",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a827126-010a-4000-aa06-a8aa716505b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazle/.local/lib/python3.10/site-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 739us/step\n",
      "\n",
      "Epoch 1: AUC-PR improved to 0.2836. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12ms/step - accuracy: 0.9660 - loss: 2.0806 - val_accuracy: 0.9833 - val_loss: 0.1653\n",
      "Epoch 2/3\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 763us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.9822 - loss: 0.3502 - val_accuracy: 0.9832 - val_loss: 0.1516\n",
      "Epoch 3/3\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.9856 - loss: 0.2524 - val_accuracy: 0.9833 - val_loss: 0.1614\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step\n",
      "Average AUC-PR: 0.1210804205674781\n"
     ]
    }
   ],
   "source": [
    "auc_prs = []\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 5\n",
    "\n",
    "# Stack and preprocess all training samples\n",
    "stacked_train_x = np.vstack(train_x)\n",
    "stacked_train_y = np.concatenate(train_y)\n",
    "\n",
    "# Create sequences from stacked training samples\n",
    "s_train_x, s_train_y = create_input_sequences(stacked_train_x, stacked_train_y, sequence_length)\n",
    "\n",
    "model_save_path = 'lstm_best.weights.h5'\n",
    "auc_pr_callback = AUC_PR_Callback(validation_data=(s_train_x, s_train_y), model_save_path=model_save_path)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0., input_shape=(sequence_length, 19)),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "class_weights = {0: 1.0, 1: 5.0}\n",
    "model.fit(s_train_x, s_train_y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[auc_pr_callback], \n",
    "          shuffle=False, class_weight=class_weights)\n",
    "model.load_weights(model_save_path)\n",
    "\n",
    "# Iterate over test_x to evaluate and calculate metrics\n",
    "for i in range(len(test_x)):\n",
    "    if len(test_x[i]) > sequence_length:\n",
    "        # Create sequences for the current test sample\n",
    "        s_test_x, s_test_y = create_input_sequences(test_x[i], test_y[i], sequence_length)\n",
    "        \n",
    "        # Predict on the test data\n",
    "        test_predictions = model.predict(s_test_x).reshape(-1)\n",
    "        \n",
    "        auc_pr = get_auc_pr(test_predictions, s_test_y)\n",
    "        \n",
    "        auc_prs.append(auc_pr)\n",
    "\n",
    "avg_auc_pr = np.mean(auc_prs)\n",
    "\n",
    "print(f'Average AUC-PR: {avg_auc_pr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fef91c-43c8-46fa-9ff2-4788263ec4b3",
   "metadata": {},
   "source": [
    "**BI-LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c289e7f2-1d33-47d5-93c1-3eed580c0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazle/.local/lib/python3.10/site-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722533774.855207   56946 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-01 11:36:14.892245: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-08-01 11:36:15.062131: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26820400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/2758\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:15\u001b[0m 180ms/step/step - accuracy: 0.9646 - loss: 1.2234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:36:23.334303: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33525500 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 934us/step\n",
      "\n",
      "Epoch 1: AUC-PR improved to 0.1493. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9646 - loss: 1.2192 - val_accuracy: 0.9798 - val_loss: 0.1128\n",
      "Epoch 2/30\n",
      "\u001b[1m 186/2758\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 819us/step accuracy: 0.9850 - loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:36:52.585561: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33525500 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861us/step\n",
      "\n",
      "Epoch 2: AUC-PR improved to 0.2548. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - accuracy: 0.9850 - loss: 0.1757 - val_accuracy: 0.9784 - val_loss: 0.1280\n",
      "Epoch 3/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 780us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.1604 - val_accuracy: 0.9804 - val_loss: 0.1095\n",
      "Epoch 4/30\n",
      "\u001b[1m 188/2758\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 810us/step accuracy: 0.9856 - loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:37:44.279238: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33525500 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 876us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.1456 - val_accuracy: 0.9769 - val_loss: 0.1219\n",
      "Epoch 5/30\n",
      "\u001b[1m 182/2758\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 838us/step accuracy: 0.9873 - loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:38:09.587209: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33525500 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 872us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.1207 - val_accuracy: 0.9767 - val_loss: 0.1147\n",
      "Epoch 6/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 811us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.9877 - loss: 0.1085 - val_accuracy: 0.9611 - val_loss: 0.2912\n",
      "Epoch 7/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 810us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12ms/step - accuracy: 0.9876 - loss: 0.1028 - val_accuracy: 0.9646 - val_loss: 0.1432\n",
      "Epoch 8/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 802us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - accuracy: 0.9875 - loss: 0.1037 - val_accuracy: 0.9538 - val_loss: 0.2683\n",
      "Epoch 9/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.2517 - val_accuracy: 0.9587 - val_loss: 0.1627\n",
      "Epoch 10/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 809us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0893 - val_accuracy: 0.9730 - val_loss: 0.1686\n",
      "Epoch 11/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 814us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.9887 - loss: 0.1003 - val_accuracy: 0.9717 - val_loss: 0.1695\n",
      "Epoch 12/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 834us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.9897 - loss: 0.0618 - val_accuracy: 0.9653 - val_loss: 0.2803\n",
      "Epoch 13/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 811us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.9895 - loss: 0.0649 - val_accuracy: 0.9760 - val_loss: 0.1681\n",
      "Epoch 14/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 812us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0617 - val_accuracy: 0.9635 - val_loss: 0.7035\n",
      "Epoch 15/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 813us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.9910 - loss: 0.0521 - val_accuracy: 0.9784 - val_loss: 0.1783\n",
      "Epoch 16/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 814us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0480 - val_accuracy: 0.9651 - val_loss: 0.2139\n",
      "Epoch 17/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 812us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.9947 - loss: 0.0426 - val_accuracy: 0.9681 - val_loss: 0.2171\n",
      "Epoch 18/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 813us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.9949 - loss: 0.0404 - val_accuracy: 0.9644 - val_loss: 1.1366\n",
      "Epoch 19/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 813us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9953 - loss: 0.0531 - val_accuracy: 0.9730 - val_loss: 0.2181\n",
      "Epoch 20/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 810us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9960 - loss: 0.0298 - val_accuracy: 0.9672 - val_loss: 0.1982\n",
      "Epoch 21/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 813us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.0269 - val_accuracy: 0.9646 - val_loss: 0.6924\n",
      "Epoch 22/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.9957 - loss: 0.0386 - val_accuracy: 0.9658 - val_loss: 0.2652\n",
      "Epoch 23/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 813us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16ms/step - accuracy: 0.9971 - loss: 0.0379 - val_accuracy: 0.9794 - val_loss: 0.1835\n",
      "Epoch 24/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 808us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0254 - val_accuracy: 0.9779 - val_loss: 0.2215\n",
      "Epoch 25/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 875us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.9949 - loss: 0.0611 - val_accuracy: 0.9762 - val_loss: 0.2315\n",
      "Epoch 26/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.9980 - loss: 0.0193 - val_accuracy: 0.9792 - val_loss: 0.1983\n",
      "Epoch 27/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 886us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.9980 - loss: 0.0169 - val_accuracy: 0.9708 - val_loss: 0.3444\n",
      "Epoch 28/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.9972 - loss: 0.0514 - val_accuracy: 0.9712 - val_loss: 0.2896\n",
      "Epoch 29/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 843us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.9980 - loss: 0.0297 - val_accuracy: 0.9689 - val_loss: 0.2391\n",
      "Epoch 30/30\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.9984 - loss: 0.0147 - val_accuracy: 0.9802 - val_loss: 0.2302\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step\n",
      "Average AUC-PR: 0.11651945101905418\n"
     ]
    }
   ],
   "source": [
    "auc_prs = []\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 5\n",
    "\n",
    "# Stack and preprocess all training samples\n",
    "stacked_train_x = np.vstack(train_x)\n",
    "stacked_train_y = np.concatenate(train_y)\n",
    "\n",
    "# Create sequences from stacked training samples\n",
    "s_train_x, s_train_y = create_input_sequences(stacked_train_x, stacked_train_y, sequence_length)\n",
    "\n",
    "model_save_path = 'bi_lstm_best.weights.h5'\n",
    "auc_pr_callback = AUC_PR_Callback(validation_data=(s_train_x, s_train_y), model_save_path=model_save_path)\n",
    "\n",
    "# Define the Bidirectional LSTM model\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0., input_shape=(sequence_length, 19)),\n",
    "    Bidirectional(LSTM(32, activation='relu')),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "class_weights = {0: 1.0, 1: 2.0}\n",
    "model.fit(s_train_x, s_train_y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[auc_pr_callback], \n",
    "          shuffle=False, class_weight=class_weights)\n",
    "model.load_weights(model_save_path)\n",
    "\n",
    "# Iterate over test_x to evaluate and calculate metrics\n",
    "auc_prs = []  # Reinitialize to avoid appending to previous results\n",
    "for i in range(len(test_x)):\n",
    "    if len(test_x[i]) > sequence_length:\n",
    "        # Create sequences for the current test sample\n",
    "        s_test_x, s_test_y = create_input_sequences(test_x[i], test_y[i], sequence_length)\n",
    "        \n",
    "        # Predict on the test data\n",
    "        test_predictions = model.predict(s_test_x).reshape(-1)\n",
    "        \n",
    "        # Assuming `get_auc_pr` function is defined to calculate AUC-PR\n",
    "        auc_pr = get_auc_pr(test_predictions, s_test_y)\n",
    "        \n",
    "        auc_prs.append(auc_pr)\n",
    "\n",
    "avg_auc_pr = np.mean(auc_prs)\n",
    "\n",
    "print(f'Average AUC-PR: {avg_auc_pr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a271a90-5f26-4b1b-a170-fa4732d0a435",
   "metadata": {},
   "source": [
    "**GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc6c290-3f1a-4495-abc1-0ad856905857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazle/.local/lib/python3.10/site-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 881us/step\n",
      "\n",
      "Epoch 1: AUC-PR improved to 0.1742. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.9421 - loss: 0.9535 - val_accuracy: 0.9793 - val_loss: 0.1718\n",
      "Epoch 2/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\n",
      "Epoch 2: AUC-PR improved to 0.2089. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.3109 - val_accuracy: 0.9796 - val_loss: 0.1679\n",
      "Epoch 3/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 845us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.2420 - val_accuracy: 0.9802 - val_loss: 0.1562\n",
      "Epoch 4/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 850us/step\n",
      "\n",
      "Epoch 4: AUC-PR improved to 0.2212. Model weights saved.\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.2255 - val_accuracy: 0.9800 - val_loss: 0.1452\n",
      "Epoch 5/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 837us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.2179 - val_accuracy: 0.9806 - val_loss: 0.1325\n",
      "Epoch 6/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 834us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.2115 - val_accuracy: 0.9795 - val_loss: 0.1262\n",
      "Epoch 7/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.9876 - loss: 0.1911 - val_accuracy: 0.9795 - val_loss: 0.1401\n",
      "Epoch 8/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 862us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.1893 - val_accuracy: 0.9799 - val_loss: 0.1474\n",
      "Epoch 9/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - accuracy: 0.9879 - loss: 0.1378 - val_accuracy: 0.9800 - val_loss: 0.1346\n",
      "Epoch 10/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 803us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.1285 - val_accuracy: 0.9786 - val_loss: 0.1468\n",
      "Epoch 11/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 813us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.1282 - val_accuracy: 0.9744 - val_loss: 0.1695\n",
      "Epoch 12/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 794us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.9919 - loss: 0.0992 - val_accuracy: 0.9774 - val_loss: 0.1580\n",
      "Epoch 13/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 920us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.9934 - loss: 0.0918 - val_accuracy: 0.9666 - val_loss: 0.1749\n",
      "Epoch 14/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.9944 - loss: 0.0789 - val_accuracy: 0.9638 - val_loss: 0.1673\n",
      "Epoch 15/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.9947 - loss: 0.0719 - val_accuracy: 0.9682 - val_loss: 0.2200\n",
      "Epoch 16/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.9955 - loss: 0.0659 - val_accuracy: 0.9714 - val_loss: 0.1969\n",
      "Epoch 17/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9955 - loss: 0.0601 - val_accuracy: 0.9781 - val_loss: 0.1863\n",
      "Epoch 18/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9961 - loss: 0.0528 - val_accuracy: 0.9819 - val_loss: 0.1737\n",
      "Epoch 19/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.9933 - loss: 0.1227 - val_accuracy: 0.9824 - val_loss: 0.1703\n",
      "Epoch 20/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 859us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.9956 - loss: 0.0517 - val_accuracy: 0.9725 - val_loss: 0.1621\n",
      "Epoch 21/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.9953 - loss: 0.0505 - val_accuracy: 0.9819 - val_loss: 0.1683\n",
      "Epoch 22/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.9969 - loss: 0.0430 - val_accuracy: 0.9722 - val_loss: 0.1751\n",
      "Epoch 23/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.9959 - loss: 0.0516 - val_accuracy: 0.9813 - val_loss: 0.1451\n",
      "Epoch 24/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.9948 - loss: 0.0661 - val_accuracy: 0.9797 - val_loss: 0.1823\n",
      "Epoch 25/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.9961 - loss: 0.2085 - val_accuracy: 0.9696 - val_loss: 0.1509\n",
      "Epoch 26/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.9952 - loss: 0.0497 - val_accuracy: 0.9797 - val_loss: 0.1596\n",
      "Epoch 27/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.9970 - loss: 0.0389 - val_accuracy: 0.9699 - val_loss: 0.1832\n",
      "Epoch 28/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.9970 - loss: 0.0505 - val_accuracy: 0.9709 - val_loss: 0.1974\n",
      "Epoch 29/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 847us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.9969 - loss: 0.0611 - val_accuracy: 0.9698 - val_loss: 0.1890\n",
      "Epoch 30/30\n",
      "\u001b[1m2757/2757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 857us/step\n",
      "\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.9977 - loss: 0.0357 - val_accuracy: 0.9706 - val_loss: 0.2274\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Average AUC-PR: 0.11590812827872007\n"
     ]
    }
   ],
   "source": [
    "auc_prs = []\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 10\n",
    "\n",
    "# Stack and preprocess all training samples\n",
    "stacked_train_x = np.vstack(train_x)\n",
    "stacked_train_y = np.concatenate(train_y)\n",
    "\n",
    "# Create sequences from stacked training samples\n",
    "s_train_x, s_train_y = create_input_sequences(stacked_train_x, stacked_train_y, sequence_length)\n",
    "\n",
    "model_save_path = 'gru_best.weights.h5'\n",
    "auc_pr_callback = AUC_PR_Callback(validation_data=(s_train_x, s_train_y), model_save_path=model_save_path)\n",
    "\n",
    "# Define the GRU model\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0., input_shape=(sequence_length, 19)),\n",
    "    GRU(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "class_weights = {0: 1.0, 1: 5.0}\n",
    "model.fit(s_train_x, s_train_y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[auc_pr_callback], \n",
    "          shuffle=False, class_weight=class_weights)\n",
    "model.load_weights(model_save_path)\n",
    "\n",
    "# Iterate over test_x to evaluate and calculate metrics\n",
    "auc_prs = []  # Reinitialize to avoid appending to previous results\n",
    "for i in range(len(test_x)):\n",
    "    if len(test_x[i]) > sequence_length:\n",
    "        # Create sequences for the current test sample\n",
    "        s_test_x, s_test_y = create_input_sequences(test_x[i], test_y[i], sequence_length)\n",
    "        \n",
    "        # Predict on the test data\n",
    "        test_predictions = model.predict(s_test_x).reshape(-1)\n",
    "        \n",
    "        # Assuming `get_auc_pr` function is defined to calculate AUC-PR\n",
    "        auc_pr = get_auc_pr(test_predictions, s_test_y)\n",
    "        \n",
    "        auc_prs.append(auc_pr)\n",
    "\n",
    "avg_auc_pr = np.mean(auc_prs)\n",
    "\n",
    "print(f'Average AUC-PR: {avg_auc_pr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433df877-2116-4f5c-81a4-16f8567e3b77",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e4c4189-a6b1-4746-81aa-f3e4dd55c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC-PR: 0.2971407897705757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Function to create input sequences\n",
    "def create_input_sequences_ft(data, labels, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequence = np.array(data[i:i + sequence_length]).flatten()  # Flatten the sequence\n",
    "        sequences.append(sequence)\n",
    "        targets.append(labels[i + sequence_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 10\n",
    "\n",
    "# Stack and preprocess all training samples\n",
    "stacked_train_x = np.vstack(train_x)\n",
    "stacked_train_y = np.concatenate(train_y)\n",
    "\n",
    "# Create sequences from stacked training samples\n",
    "s_train_x, s_train_y = create_input_sequences_ft(stacked_train_x, stacked_train_y, sequence_length)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "s_train_x = scaler.fit_transform(s_train_x)\n",
    "\n",
    "# Define the SVM model with 'rbf' kernel\n",
    "svm_model = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(s_train_x, s_train_y)\n",
    "\n",
    "# Iterate over test_x to evaluate and calculate metrics\n",
    "auc_prs = []\n",
    "for i in range(len(test_x)):\n",
    "    if len(test_x[i]) > sequence_length:\n",
    "        # Create sequences for the current test sample\n",
    "        s_test_x, s_test_y = create_input_sequences_ft(test_x[i], test_y[i], sequence_length)\n",
    "        \n",
    "        # Scale the test data\n",
    "        s_test_x = scaler.transform(s_test_x)\n",
    "        \n",
    "        # Predict on the test data\n",
    "        test_predictions = svm_model.predict(s_test_x)\n",
    "        \n",
    "        # Calculate AUC-PR\n",
    "        auc_pr = get_auc_pr(test_predictions, s_test_y)\n",
    "        \n",
    "        auc_prs.append(auc_pr)\n",
    "\n",
    "avg_auc_pr = np.mean(auc_prs)\n",
    "\n",
    "print(f'Average AUC-PR: {avg_auc_pr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d5dcb-31e3-4cfb-afc2-a4a25d73c6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0624b-734c-410c-afc2-53840d6d6642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f741de1-6793-4481-9c5b-3b21cef24ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
