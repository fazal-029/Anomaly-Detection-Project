{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9130a397-96c0-4134-8475-e48de854f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 01:41:44.200788: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 01:41:44.219151: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 01:41:44.223759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 01:41:44.236604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 01:41:44.972087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51c7f78-820f-46ec-a4ff-4f574da87227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52,)\n",
      "(52,)\n",
      "(31,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.load('spark_0_trace-scl_std/train.npy', allow_pickle=True)\n",
    "test_x = np.load('spark_0_trace-scl_std/test.npy', allow_pickle=True)\n",
    "train_y = np.load('spark_0_trace-scl_std/y_train.npy', allow_pickle=True)\n",
    "test_y = np.load('spark_0_trace-scl_std/y_test.npy', allow_pickle=True)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32422380-37fe-4283-9d63-2bb11681ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, _ in enumerate(test_y):\n",
    "    test_y[j] = (test_y[j] != 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe51ed-3805-4259-b102-1224a1d86753",
   "metadata": {},
   "source": [
    "# Time Series Modeling - Statistical Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d8bfb4-9618-4c27-b458-7ccb6d8c7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import auc\n",
    "from prts import ts_precision, ts_recall\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa81ee7-4501-46d9-8c67-15e0f7eb1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall(real, pred):\n",
    "    try:\n",
    "        precision = ts_precision(real, pred, alpha=0.0, cardinality=\"reciprocal\", bias=\"flat\")\n",
    "        recall = ts_recall(real, pred, alpha=0.0, cardinality=\"reciprocal\", bias=\"flat\")\n",
    "    except AssertError:\n",
    "        precision = 0.0\n",
    "        recall = 0.0\n",
    "    return precision, recall\n",
    "\n",
    "# Function to calculate AUC - Precision Recall\n",
    "def auc_pr_range_based(precisions, recalls):\n",
    "    # Sort recall values in ascending order and adjust precisions accordingly\n",
    "    sorted_indices = np.argsort(recalls)\n",
    "    sorted_recalls = np.array(recalls)[sorted_indices]\n",
    "    sorted_precisions = np.array(precisions)[sorted_indices]\n",
    "    \n",
    "    return auc(sorted_recalls, sorted_precisions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7eda96-6c1b-4f84-9bba-87f8fdceb0e6",
   "metadata": {},
   "source": [
    "**Vector Autoregression (VAR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf0089f-d61d-4448-9d9e-c5df6fcaf0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.11327868635519465\n",
      "Average Recall: 0.7844774427578162\n",
      "Average F1 score: 0.19797040935534826\n",
      "Average AUC-PR: 0.24583324912294638\n"
     ]
    }
   ],
   "source": [
    "all_precisions = []\n",
    "all_recalls = []\n",
    "lag = 10\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_x = np.concatenate(train_x, axis=0)\n",
    "train_data_x = scaler.fit_transform(train_data_x)\n",
    "model = sm.tsa.VAR(train_data_x).fit(lag)\n",
    "\n",
    "for test_record, true_values in zip(test_x, test_y):\n",
    "    test_record = scaler.transform(test_record)\n",
    "    predictions = model.forecast(train_data_x[-lag:], steps=len(test_record))\n",
    "    predictions = predictions.mean(axis=1)\n",
    "\n",
    "    residuals = np.abs(true_values - predictions)\n",
    "    \n",
    "    lower = np.quantile(residuals, 0.3)\n",
    "    upper = np.quantile(residuals, 0.7)\n",
    "    bin_pred = ((predictions > upper) | (predictions < lower)).astype(int)\n",
    "    \n",
    "    precision, recall = get_precision_recall(true_values, bin_pred)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "\n",
    "# Optionally, you can compute average precision and recall\n",
    "average_precision = np.mean(all_precisions)\n",
    "average_recall = np.mean(all_recalls)\n",
    "auc_score = auc_pr_range_based(all_precisions, all_recalls)\n",
    "f1_score = 2 * average_precision * average_recall / (average_precision + average_recall)\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 score: {f1_score}\")\n",
    "print(f'Average AUC-PR: {auc_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e798c5f-5d3b-4127-84e8-7db050e93d79",
   "metadata": {},
   "source": [
    "# Semi Supervised Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b26c8-c231-49bd-b1bc-0aef1f51567a",
   "metadata": {},
   "source": [
    "**LSTM autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dba927-cb5e-4f57-baf6-918ec35900dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722411150.735916   26963 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 01:32:30.898166: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 1.0732 - val_loss: 0.9936\n",
      "Epoch 2/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9547 - val_loss: 0.9833\n",
      "Epoch 3/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9425 - val_loss: 2.8506\n",
      "Epoch 4/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9326 - val_loss: 1.0804\n",
      "Epoch 5/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9255 - val_loss: 0.9977\n",
      "Epoch 6/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9193 - val_loss: 0.9982\n",
      "Epoch 7/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9271 - val_loss: 1.4750\n",
      "Epoch 8/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9179 - val_loss: 0.9636\n",
      "Epoch 9/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9130 - val_loss: 1.9230\n",
      "Epoch 10/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9054 - val_loss: 1.0505\n",
      "Epoch 11/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8984 - val_loss: 1.1336\n",
      "Epoch 12/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8951 - val_loss: 0.9524\n",
      "Epoch 13/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8929 - val_loss: 1.1879\n",
      "Epoch 14/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.9043 - val_loss: 1.9394\n",
      "Epoch 15/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8894 - val_loss: 0.9616\n",
      "Epoch 16/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8861 - val_loss: 1.0305\n",
      "Epoch 17/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8816 - val_loss: 1.0584\n",
      "Epoch 18/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8876 - val_loss: 2.1410\n",
      "Epoch 19/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8628 - val_loss: 1.0475\n",
      "Epoch 20/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8660 - val_loss: 0.9876\n",
      "Epoch 21/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8704 - val_loss: 1.3713\n",
      "Epoch 22/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8435 - val_loss: 1.0099\n",
      "Epoch 23/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.8429 - val_loss: 1.0527\n",
      "Epoch 24/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.8449 - val_loss: 3.7571\n",
      "Epoch 25/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 0.8448 - val_loss: 1.2690\n",
      "Epoch 26/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.8361 - val_loss: 0.9532\n",
      "Epoch 27/150\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.8635 - val_loss: 1.1608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Average Precision: 0.738256581380362\n",
      "Average Recall: 0.12286108113836679\n",
      "Average F1 score: 0.21066343356749626\n",
      "AUC-PR: 0.44172241178584154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def create_lstm_autoencoder(input_shape):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]))\n",
    "    \n",
    "    # Encoder\n",
    "    encoded = LSTM(128, activation='relu', return_sequences=True)(inputs)\n",
    "    encoded = Dropout(0.2)(encoded)\n",
    "    encoded = LSTM(64, activation='relu')(encoded)\n",
    "    encoded = BatchNormalization()(encoded)\n",
    "    encoded = RepeatVector(input_shape[1])(encoded)\n",
    "    \n",
    "    # Decoder\n",
    "    decoded = LSTM(64, activation='relu', return_sequences=True)(encoded)\n",
    "    decoded = Dropout(0.2)(decoded)\n",
    "    decoded = LSTM(128, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = BatchNormalization()(decoded)\n",
    "    \n",
    "    outputs = TimeDistributed(Dense(input_shape[2]))(decoded)\n",
    "    \n",
    "    autoencoder = Model(inputs, outputs)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "# Preprocess data\n",
    "scaler = StandardScaler()\n",
    "train_data_x = np.concatenate(train_x, axis=0)\n",
    "train_data_x = scaler.fit_transform(train_data_x.reshape(-1, train_data_x.shape[-1]))\n",
    "\n",
    "# Reshape data to have shape (samples, time steps, features)\n",
    "time_steps = 10  # choose an appropriate time step length\n",
    "train_data_x = train_data_x.reshape(-1, time_steps, train_data_x.shape[-1])\n",
    "input_shape = train_data_x.shape\n",
    "\n",
    "# Create and train the model with EarlyStopping\n",
    "autoencoder = create_lstm_autoencoder(input_shape)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "autoencoder.fit(train_data_x, train_data_x, epochs=150, batch_size=32, validation_split=0.2, callbacks=[early_stopping], shuffle = False)\n",
    "\n",
    "# Evaluate model on test data\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "\n",
    "for test_record, true_values in zip(test_x, test_y):\n",
    "    test_record = scaler.transform(test_record.reshape(-1, test_record.shape[-1]))\n",
    "\n",
    "    # Pad the test_record to be a multiple of time_steps\n",
    "    if len(test_record) % time_steps != 0:\n",
    "        pad_length = time_steps - (len(test_record) % time_steps)\n",
    "        test_record = np.pad(test_record, ((0, pad_length), (0, 0)), 'constant')\n",
    "\n",
    "    test_record = test_record.reshape(-1, time_steps, test_record.shape[-1])\n",
    "    \n",
    "    predictions = autoencoder.predict(test_record)\n",
    "    \n",
    "    predictions = predictions.reshape(-1, predictions.shape[-1])[:len(true_values)]\n",
    "    test_record = test_record.reshape(-1, test_record.shape[-1])[:len(true_values)]\n",
    "    residuals = np.abs(test_record - predictions).mean(axis=1)\n",
    "    \n",
    "    mean_residual = np.mean(residuals)\n",
    "    std_residual = np.std(residuals)\n",
    "    threshold_upper = mean_residual + 2 * std_residual\n",
    "    threshold_lower = mean_residual - 2 * std_residual\n",
    "    \n",
    "    bin_pred = ((residuals > threshold_upper) | (residuals < threshold_lower)).astype(int)\n",
    "    bin_true = (true_values != 0).astype(int)  # assuming true_values contains binary labels\n",
    "    \n",
    "    precision, recall = get_precision_recall(bin_true, bin_pred)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "\n",
    "average_precision = np.mean(all_precisions)\n",
    "average_recall = np.mean(all_recalls)\n",
    "auc_score = auc_pr_range_based(all_precisions, all_recalls)\n",
    "f1_score = 2 * average_precision * average_recall / (average_precision + average_recall)\n",
    "\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 score: {f1_score}\")\n",
    "print(f\"AUC-PR: {auc_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33cdb3e-fcf0-479c-9a3b-dbab10c95e5e",
   "metadata": {},
   "source": [
    "**Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85e44adc-e428-4359-a6d0-5b6b37d84760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - loss: 1.2466 - val_loss: 0.9856\n",
      "Epoch 2/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9707 - val_loss: 0.9539\n",
      "Epoch 3/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9042 - val_loss: 0.9371\n",
      "Epoch 4/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.9412 - val_loss: 0.9295\n",
      "Epoch 5/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9537 - val_loss: 0.9203\n",
      "Epoch 6/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.9304 - val_loss: 0.9167\n",
      "Epoch 7/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.8832 - val_loss: 0.9206\n",
      "Epoch 8/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.8976 - val_loss: 0.9129\n",
      "Epoch 9/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9662 - val_loss: 0.9135\n",
      "Epoch 10/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.9856 - val_loss: 0.9085\n",
      "Epoch 11/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.8648 - val_loss: 0.9098\n",
      "Epoch 12/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9328 - val_loss: 0.9049\n",
      "Epoch 13/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9283 - val_loss: 0.9062\n",
      "Epoch 14/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9445 - val_loss: 0.9015\n",
      "Epoch 15/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.9792 - val_loss: 0.9039\n",
      "Epoch 16/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.8940 - val_loss: 0.9043\n",
      "Epoch 17/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9673 - val_loss: 0.9012\n",
      "Epoch 18/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.8879 - val_loss: 0.9025\n",
      "Epoch 19/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9263 - val_loss: 0.9033\n",
      "Epoch 20/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 0.9573 - val_loss: 0.9001\n",
      "Epoch 21/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9451 - val_loss: 0.9033\n",
      "Epoch 22/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.9024 - val_loss: 0.9023\n",
      "Epoch 23/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.8991 - val_loss: 0.9067\n",
      "Epoch 24/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 0.9029 - val_loss: 0.8995\n",
      "Epoch 25/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 0.9556 - val_loss: 0.9006\n",
      "Epoch 26/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.9015 - val_loss: 0.8999\n",
      "Epoch 27/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 0.9362 - val_loss: 0.9030\n",
      "Epoch 28/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.9376 - val_loss: 0.9006\n",
      "Epoch 29/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9988 - val_loss: 0.8990\n",
      "Epoch 30/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9783 - val_loss: 0.9036\n",
      "Epoch 31/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9779 - val_loss: 0.9021\n",
      "Epoch 32/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.8729 - val_loss: 0.8988\n",
      "Epoch 33/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.8724 - val_loss: 0.8963\n",
      "Epoch 34/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9432 - val_loss: 0.8977\n",
      "Epoch 35/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.9300 - val_loss: 0.8952\n",
      "Epoch 36/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.9303 - val_loss: 0.8941\n",
      "Epoch 37/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9804 - val_loss: 0.8944\n",
      "Epoch 38/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9110 - val_loss: 0.8936\n",
      "Epoch 39/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9393 - val_loss: 0.8963\n",
      "Epoch 40/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.9322 - val_loss: 0.8959\n",
      "Epoch 41/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.8764 - val_loss: 0.8998\n",
      "Epoch 42/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9417 - val_loss: 0.9011\n",
      "Epoch 43/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9238 - val_loss: 0.8980\n",
      "Epoch 44/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.9152 - val_loss: 0.9002\n",
      "Epoch 45/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.9342 - val_loss: 0.9068\n",
      "Epoch 46/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.9396 - val_loss: 0.8969\n",
      "Epoch 47/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.9566 - val_loss: 0.8971\n",
      "Epoch 48/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 0.8926 - val_loss: 0.8957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Average Precision: 0.353450454053773\n",
      "Average Recall: 0.6748227430531898\n",
      "Average F1 score: 0.46391640978103144\n",
      "Average AUC-PR: 0.4068349786443972\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, RepeatVector, TimeDistributed, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "def create_transformer_autoencoder(input_shape, embed_dim=30, num_heads=4, ff_dim=128, num_layers=4, rate=0.1):\n",
    "    time_steps, num_features = input_shape[1], input_shape[2]\n",
    "\n",
    "    inputs = Input(shape=(time_steps, num_features))\n",
    "    x = Dense(embed_dim)(inputs)  # Ensure input dimension matches embed_dim\n",
    "    for _ in range(num_layers):\n",
    "        x = TransformerEncoderLayer(embed_dim, num_heads, ff_dim, rate)(x, training=True)\n",
    "    \n",
    "    encoded = GlobalAveragePooling1D()(x)\n",
    "    encoded = Dense(embed_dim, activation='relu')(encoded)\n",
    "\n",
    "    # Decoding part\n",
    "    decoded = RepeatVector(time_steps)(encoded)\n",
    "    for _ in range(num_layers):\n",
    "        decoded = TransformerEncoderLayer(embed_dim, num_heads, ff_dim, rate)(decoded, training=True)\n",
    "    \n",
    "    decoded = TimeDistributed(Dense(num_features))(decoded)\n",
    "\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "# Example reshaping of train_data_x\n",
    "time_steps = 30\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_x = np.concatenate(train_x, axis=0)\n",
    "train_data_x = scaler.fit_transform(train_data_x.reshape(-1, train_data_x.shape[-1]))\n",
    "\n",
    "# Ensure there is enough data to reshape\n",
    "if len(train_data_x) >= time_steps:\n",
    "    num_samples = (len(train_data_x) // time_steps) * time_steps\n",
    "    train_data_x = train_data_x[:num_samples]  # Truncate to a multiple of time_steps\n",
    "    num_features = train_data_x.shape[1]\n",
    "    train_data_x = train_data_x.reshape(-1, time_steps, num_features)\n",
    "    input_shape = train_data_x.shape\n",
    "\n",
    "    autoencoder = create_transformer_autoencoder(input_shape)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    autoencoder.fit(train_data_x, train_data_x, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "\n",
    "    for test_record, true_values in zip(test_x, test_y):\n",
    "        padded_length = ((len(test_record) // time_steps) + 1) * time_steps\n",
    "        padded_test_record = np.pad(test_record, ((0, padded_length - len(test_record)), (0, 0)), mode='constant')\n",
    "        padded_test_record = padded_test_record.reshape(-1, time_steps, num_features)\n",
    "        predictions = autoencoder.predict(padded_test_record)\n",
    "        \n",
    "        predictions = predictions.reshape(-1, predictions.shape[-1])[:len(true_values)]\n",
    "        predictions = predictions.mean(axis=1)\n",
    "    \n",
    "        # Calculate residuals\n",
    "        residuals = np.abs(true_values - predictions)\n",
    "    \n",
    "        lower = np.quantile(residuals, 0.18)\n",
    "        upper = np.quantile(residuals, 0.85)\n",
    "\n",
    "        bin_pred = ((residuals > upper) | (residuals < lower)).astype(int)\n",
    "        \n",
    "        precision, recall = get_precision_recall(true_values, bin_pred)\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "\n",
    "    average_precision = np.mean(all_precisions)\n",
    "    average_recall = np.mean(all_recalls)\n",
    "    auc_score = auc_pr_range_based(all_precisions, all_recalls)\n",
    "    f1_score = 2 * average_precision * average_recall / (average_precision + average_recall)\n",
    "    print(f\"Average Precision: {average_precision}\")\n",
    "    print(f\"Average Recall: {average_recall}\")\n",
    "    print(f\"Average F1 score: {f1_score}\")\n",
    "    print(f'Average AUC-PR: {auc_score}')\n",
    "else:\n",
    "    print(\"Not enough data to reshape for the specified time_steps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0ceb9-e5af-4697-8f2c-f5b4efd67e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed0813-bf63-473c-8355-797d3ed0a01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b66dae-85b9-45e4-817f-452c70ca7f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bcd4bc-71d1-4f2c-b5e1-f5d9c0e4179c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bb91c-d2a8-4070-8aee-6d4a08d4c426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2beaf-c4fe-472c-b9ef-67203159feac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
